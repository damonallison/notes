# Education

## Goals

* Strong understanding machine learning, AI, and deep learning.

## Questions

* What are the primary tools in the DS toolkit?
  * Relational DB preferences?

## TODO

### Languages

* Python
* SQL

### Libraries

* Pandas
* Sklearn
* matplotlib

### Tools

* PostreSQL
* NoSQL : Mongo and/or Cassandra


### Math

* Linear Algebra (matrix multiplication, manipulation)
* Calculus (maximizing and minimizing algebraic equations)
* OLAP vs. OLTP

* **Spark**
  * When to use it, when not to use it?
  * Spark WebUI

* Statistics
* Linear Algebra
* Airflow

* Relational DB Modeling
  * Schema fundamentals - normalization and denormalized schemas (STAR and
    Snowflake)
  * Indexing
  * Create OLAP cubes - Fact & Dimension tables

* Document DB Modeling
  * Primary key selection, clustering column selection.
  * Mongo, Cassandra

* Apache Airflow
  * How to build data pipelines?


## Programs

### Udacity

##### Data Engineering Nanodegree Program

The focus of this class is working with databases, data sets, and data movement
(pipelines). This class is more about collecting (ETL), storing, and moving
data. It's not about analysis or algorithms to process the data.

* 110 hours, 5 months
* Course 1: Data Modeling - Document & Relational DBs (OLAP vs. OLTP)
* Course 2: Cloud Data Warehouses - running data in AWS
* Course 3: Data Lakes w/ Spark
* Course 4: Automate Data Pipelines (Apache Airflow)

#### Data Science Nanodegree Program

This class is much more technical and engineering based - more advanced than the
Data Engineering Nanodegree. 7 months total over 2 terms.

Optional texts:
  * Elements of Statistical Learnin
  * Machine Learning: A Probabilistic Perspective
  * Python Machine Learning

It expects that you understand

* Programming
  * Python, SQL, NumPy, Pandas

* Probability / Statistics
  * Descriptive statistics - estimating distribution, center, spread.
  * Inferential statistics - sampling statistics, hypothesis testing.
  * Probability - theory, conditional probability.

* Math
  * Linear Algebra (matrix manipulation, multiplication)
  * Calculus (maximizing and minimizing algebraic equations), data cleaning with
    SkLearn and Pandas.

* Visualization with matplotlib

* Goals
  * Use Python and SQL to analycs data from different sources.
  * Use statistics and probability to design and execute A/B tests and
    recommendation engines to make data driven decisions.
  * Build / tune ML models, compare model performance (accuracy).
  * Deploy DS solutions using a basic flask app.
  * Manipulate / analyze data at scale using Spark.

##### Term1 : Machine Learning for Data Scientists

###### Project 1: Finding Donors for CharityML with Kaggle

Build an algorithm which identifies potential donors. You test multiple models
to determine which one performs the best.

* Regression: Distinguish between regression and classification. Prediction
  using Logistic Regression
* Decision Trees
* Naive Bayes. Train models using Bayesian Learning. Use Bayesian Inference to
  create Bayesian Networks of several variables.
* Support Vector Machines
* Ensemble of Learners: Random Forests, boosting, AdaBoost
* Evaluation: Determine accuracy, precision, recall to measure model
  performance.

###### Project 2: Image Classifer

