# Education

## Goals

* Strong understanding machine learning, AI, and deep learning.

## Questions

* What are the primary tools in the DS toolkit?
  * Relational DB preferences?

## TODO

### Languages

* Python
* SQL

### Libraries

* Pandas
* Sklearn
* matplotlib

### Tools

* PostreSQL
* NoSQL : Mongo and/or Cassandra


### Math

* Linear Algebra (matrix multiplication, manipulation)
* Calculus (maximizing and minimizing algebraic equations)
* OLAP vs. OLTP

* **Spark**
  * When to use it, when not to use it?
  * Spark WebUI

* Statistics
* Linear Algebra
* Airflow

* Relational DB Modeling
  * Schema fundamentals - normalization and denormalized schemas (STAR and
    Snowflake)
  * Indexing
  * Create OLAP cubes - Fact & Dimension tables

* Document DB Modeling
  * Primary key selection, clustering column selection.
  * Mongo, Cassandra

* Apache Airflow
  * How to build data pipelines?


## Programs

### Udacity

##### Data Engineering Nanodegree Program

The focus of this class is working with databases, data sets, and data movement
(pipelines). This class is more about collecting (ETL), storing, and moving
data. It's not about analysis or algorithms to process the data.

* 110 hours, 5 months
* Course 1: Data Modeling - Document & Relational DBs (OLAP vs. OLTP)
* Course 2: Cloud Data Warehouses - running data in AWS
* Course 3: Data Lakes w/ Spark
* Course 4: Automate Data Pipelines (Apache Airflow)

#### Data Science Nanodegree Program

This class is much more technical and engineering based. It expects that you
understand Python, SQL, Linear Algebra (matrix manipulation, multiplication),
Calculus (maximizing and minimizing algebraic equations), data cleaning with SkLearn and Pandas.
