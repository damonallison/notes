# Week 1 : Big Data - Capstone Project

* Week 1/2 : Data Analysis w/ Splunk / Open Office
* Week 3/4 : KNIME, MLLib / Gephi
* Week 5   : Reports / Slides

### Feedback

* Teach the splunk query syntax prior to writing queries.
    * Same as `Cypher` when learning `Neo4j`. We didn't learn cypher first.

##  Final Project

* 10 minute slide presentation w/ written script.
    * [Presentation](https://docs.google.com/presentation/d/1OO82dc8Mv0rPeml3ZdVnIXF3IUXWpiS4XZ9nUA-Ems8/edit?usp=sharing)

* Technical appendix. Built each week, reviewed with peers.

Analyze game data. Game play / social behavior/ ad targeting.

## Introduction to the Capstone Project

### Catch the Pink Flamingo : Game Play Introduction

* Players (or teams?) must have at least 1 point in every map grid cell to advance levels.
* Missions change in real time.
* Example : "Catch the flamingos on land with stars on their belly"
* User gets `+1` for a score tap, `-2` for an invalid tap.
* Level 1 : Training level. (team by yourself)
* After level 1, user joins (or creates) a team. Teams of 1 are allowed.

#### Data Elements

##### Ranking of Users

* Users are ranked on speed and accuracy.
* Other users can see a user's map.
* Users are categorized into categories:
    * "rising star", "veteran", "coach", "social butterfly", "hot flamingo"

##### Ranking of Teams

* Teams are ranked / shown publicly.
* 30 member team max / min 1.
* Players ask to join a team, require 80% of team members to approve.
* Teams can recruit and outvote a player.
* Users who switch teams bring their points to a new team.

##### In-game Purchases

* Binoculars to spot mission specific flamingos.
* Special flamingos which count for > 1 point.
* Ice blocks to freeze a mission for 20 secionds.
* Trading cards to transfer extra points between grid cells.

##### Game Completion

* The game never ends. We must keep making it more challenging.


### A conceptual Schema for Catch the Pink Flamingo

#### ERD (User / Team / Session)

* User
    * timestamp (creation date)
* Team
    * strength
* Team Assignment :user / team assignment
* LevelEvents
* User_Sessions : Which users are playing during a session. teamLevel / platform.
* AdClicks / BuyClicks : tied to a session.
* GameClicks : keep track of each user click. Hit flamingo? Correct?

#### Graph (Chat)

* User / Team / Chat Session / Chat Item
* Each team has a single chat session at a time.
* A "Chat Item" is a unique message. No text is analyzed as part of this project.



## Acquiring, Exploring, and Preparing the Data

* Splunk installs into: `/opt/splunk`
* `$ splunk start`
* `http://localhost:8000`
* username : admin
* password : asdfasdf

* What operating systems are users using?
    * `source="/home/cloudera/big-data/big-data-capstone/flamingo-data/user-session.csv" | stats count by platformType`
* What are the two most commonly clicked ads?
    * `source="/home/cloudera/big-data/big-data-capstone/flamingo-data/ad-clicks.csv" | stats count by adCategory | sort 2 -num(count)`
* What are the two most commonly purchased products?
    * `source="/home/cloudera/big-data/big-data-capstone/flamingo-data/buy-clicks.csv" | stats count by buyId | sort 2 -num(count)`
* What is the average team size?
    * `source="/home/cloudera/big-data/big-data-capstone/flamingo-data/team-assignments.csv" | stats count by team | stats avg(count)`
* How many users made a purchase?
    * `source="/home/cloudera/big-data/big-data-capstone/flamingo-data/buy-clicks.csv" | stats count values(userId)`
* Who made the most purchases?
    * `source="/home/cloudera/big-data/big-data-capstone/flamingo-data/buy-clicks.csv" | stats count by userId | sort 1 by -count`

### Aggregate Calculations

* What is the hit ratio?
    * `source="/home/cloudera/big-data/big-data-capstone/flamingo-data/game-clicks.csv" | stats avg(isHit)`

* Find min / max price and total price paid by users
    * `source="buy-clicks.csv" | stats min(price), max(price), sum(price)`

* Filtering w/ Aggregation
    * Average team level for windows users
        * `source="user-session.csv" platformType="windows" sessionType="end" | stats avg(teamLevel)`
    * Average team level for iPhone or mac.
        * `source="user-session.csv" (platformType="iphone" OR platformType="mac") sessionType="end" | stats avg(teamLevel)`

* Filter and projection using `table`
    * `table` allows you to select (project) which fields to return.
    * `source="user-session.csv" sessionType=end teamLevel=2 platformType=android | table userId, platformType | sort num(userId)`

### Quiz : Data Exploration With Splunk

* The ad-click events are listed in the file ad-clicks.csv. Each advertisement that is clicked on by a user generates $0.50 of revenue. What is the total amount of revenue generated by the ad-click events?
    * How many ads were clicked on?
    * `source="ad-clicks.csv" | count` == 16323 == `8161.50`

* How many different categories of advertisements are there?
    * `source="ad-clicks.csv" | stats count by adCategory` = 9

* Letâ€™s say electronics generates $0.75, and the other types of advertisements generate $0.40. What is the total amount of revenue?
    * Electronics = 1097 * .75 == 822.75
    * Rest = (16323 - 1097) = 15226 * .40 = 6090.40
    * 822.75 + 6090.40 = `6913`.15

* The file buy-clicks.csv lists the in-app purchases and the price of each purchase. When a user purchases an item, the company gets 2% of the price. How much revenue does the company make from the purchases in buy-clicks.csv?
    * What is the total revenue paid by users?
        * `source="buy-clicks.csv" | stats sum(price)` = 21407 * .02 = `428.14`

* How many distinct items can be purchased?
    * Note that this answer is not correct. There could be products advertised which were *not* purchased. We **should** query into `ad-clicks.csv`, however `ad-clicks` does not have a field for the product being advertised.
    * `source="buy-clicks.csv" | stats count by (buyId)` == 6

* How much does the most expensive item cost?
    * `source="buy-clicks.csv" | stats max(price)` == 20.0

* What is the buyId of the item that is purchased the most?
    * `source="buy-clicks.csv" | stats count by buyId | sort - count` == 2

### Peer Graded Assignment : Data Exploration Technical Appendix

* Provide a quick review of the data files available for analysis.
* Report your key findings from your aggregation analysis.
* Report on your key findings from your filtering analysis.

* Filtering and aggregation example grouping by a field. Note the `by userId`.
    * What is the isHit ratio for users 417 and 12?
    * `source="game-clicks.csv" userId = 417 OR userId = 12 | stats avg(isHit) by userId`



## Week 2

### Classification in KNIME (Review)

* Goal: predict low humidity days.
    * High air pressure + high temp (warm) + wind from the East (dry) == low humidity

### Assignment

* Read in the data from the file combined_data.csv. Identify the number of samples.
    * 4619

* Filter samples (i.e., rows) to only contain those with purchases and identify that number. NOTE: You will need to add a new node to your KNIME workflow for this. The new node should be placed between the File Reader and Color Manager nodes.
    * 1411

### Decision Tree Analysis

* What makes a user a HighRoller? Draw some insights from your analysis. Hint: Look at the resulting decision tree.
    * The OS the player uses.

* Give 2 recommendations to increase revenue you would propose based on these insights.
    * Offer promotions to iOS / Android users.
    * Reposition development effort around iOS / Android products.


## Week 3 : Clustering Analysis

```
// to start pyspark

// must be in the capstone project. ./lib/ contains
// spark-csv

cd /home/cloudera/big-data/courseraDataSimulation/capstone
$ pyspark --packages com.databricks:spark-csv_2.10:1.5.0
```

* How would you cluster users?
    * Game playing behavior.
    * Purchasing history.
    * Ad effectiveness.

* How many clusters?
    * What is the variation / number of features you are looking at?

### Final Data Format

* Team level
* Ad Clicks
* Buy Clicks (or total revenue)

* Need to combine from different data sources.

