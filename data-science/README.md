# Data Science

## Kafka

* A distributed streaming platform used for building real time pipelines.
* Based around topics, partitions, producers, and consumers.

## Hadoop

* A distributed, fault tolerant, scalable, redundant file system (HDFS).
* A distributed MapReduce programming framework.

## Spark

* An distribued, in-memory, parallel data processing engine.
* Based on RDDs - Resilient Distributed Datasets.
* Spark SQL - Provides distributed SQL like operations (query, filter, sort) on large datasets.

## Hive

* Provides a SQL-like interface (HiveQL) which operates on databases and file systems which integrate with Hadoop.
* Abstracts away the underlying Hadoop / Java MapReduce API into a user friendly SQL interface.

## Anaconda

* A distribution of the Python and R which simplifies package management and deployment.
* Package versions are managed by the package manager `conda`.

## Flume 

* Flume is a kafka-like streaming engine with tight integration with Hadoop.
* Kafka is a much better general purpose streaming engine than Flume. tl;dr - Use Kafka.
* Flume is tightly integrated with Hadoop / HDFS and is generally used to ingest data into HDFS.

---

## Pandas

* Provides high level data structures (Series, Dataframe) and tools for data analysis and manipulation.
* Pandas is built on top of NumPy.

## SciPy / NumPy

* A scientific computing library for Python.
* NumPy provides data structures for large, multi-dimensional arrays and matrices.
* SciPy builds on the NumPy array object.
* SciPy provides high level mathematical functions to operate on NumPy data structures.
* SciPy includes algorithms for clustering, image processing, linear algebra, spacial (kNN, distance), others.

## Matplotlib

* 2D plotting library.

